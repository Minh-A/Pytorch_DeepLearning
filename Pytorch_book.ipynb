{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1월4일.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOBYLghy0h6YrL2mV1V2YK+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Minh-A/Pytorch_DeepLearning/blob/main/Pytorch_book.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVpR6PIxqGoZ"
      },
      "source": [
        "1월 4일: 책 5강"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TthsXDrkeqK0"
      },
      "source": [
        "# 파이토치 라이브러리 임포트\r\n",
        "import torch\r\n",
        "from torch.autograd import Variable\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "from torch.utils.data import DataLoader, TensorDataset\r\n",
        "\r\n",
        "# sklearn 라이브러리 임포트\r\n",
        "from sklearn.datasets import load_wine\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "# pandas 라이브러리 임포트\r\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO01f3JnjYUF",
        "outputId": "7fe78609-0275-4f47-e3a4-e85d3179f3f5"
      },
      "source": [
        "wine = load_wine()\r\n",
        "wine"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n',\n",
              " 'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
              "         1.065e+03],\n",
              "        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
              "         1.050e+03],\n",
              "        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
              "         1.185e+03],\n",
              "        ...,\n",
              "        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
              "         8.350e+02],\n",
              "        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
              "         8.400e+02],\n",
              "        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
              "         5.600e+02]]),\n",
              " 'feature_names': ['alcohol',\n",
              "  'malic_acid',\n",
              "  'ash',\n",
              "  'alcalinity_of_ash',\n",
              "  'magnesium',\n",
              "  'total_phenols',\n",
              "  'flavanoids',\n",
              "  'nonflavanoid_phenols',\n",
              "  'proanthocyanins',\n",
              "  'color_intensity',\n",
              "  'hue',\n",
              "  'od280/od315_of_diluted_wines',\n",
              "  'proline'],\n",
              " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2]),\n",
              " 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "tJ5xd0gJjYYs",
        "outputId": "29d5d0d6-cacc-453a-bf00-4a0999810f94"
      },
      "source": [
        "pd.DataFrame(wine.data, columns= wine.feature_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>13.71</td>\n",
              "      <td>5.65</td>\n",
              "      <td>2.45</td>\n",
              "      <td>20.5</td>\n",
              "      <td>95.0</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.06</td>\n",
              "      <td>7.70</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.74</td>\n",
              "      <td>740.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>13.40</td>\n",
              "      <td>3.91</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.41</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>750.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>13.27</td>\n",
              "      <td>4.28</td>\n",
              "      <td>2.26</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.35</td>\n",
              "      <td>10.20</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.56</td>\n",
              "      <td>835.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>13.17</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.37</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.46</td>\n",
              "      <td>9.30</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.62</td>\n",
              "      <td>840.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>14.13</td>\n",
              "      <td>4.10</td>\n",
              "      <td>2.74</td>\n",
              "      <td>24.5</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.20</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.60</td>\n",
              "      <td>560.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     alcohol  malic_acid   ash  ...   hue  od280/od315_of_diluted_wines  proline\n",
              "0      14.23        1.71  2.43  ...  1.04                          3.92   1065.0\n",
              "1      13.20        1.78  2.14  ...  1.05                          3.40   1050.0\n",
              "2      13.16        2.36  2.67  ...  1.03                          3.17   1185.0\n",
              "3      14.37        1.95  2.50  ...  0.86                          3.45   1480.0\n",
              "4      13.24        2.59  2.87  ...  1.04                          2.93    735.0\n",
              "..       ...         ...   ...  ...   ...                           ...      ...\n",
              "173    13.71        5.65  2.45  ...  0.64                          1.74    740.0\n",
              "174    13.40        3.91  2.48  ...  0.70                          1.56    750.0\n",
              "175    13.27        4.28  2.26  ...  0.59                          1.56    835.0\n",
              "176    13.17        2.59  2.37  ...  0.60                          1.62    840.0\n",
              "177    14.13        4.10  2.74  ...  0.61                          1.60    560.0\n",
              "\n",
              "[178 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrgJW3cTjYbR",
        "outputId": "67d48a1d-3be0-46f0-9c5a-a0740da5bb21"
      },
      "source": [
        "wine.target"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9ObSk3CjYdb"
      },
      "source": [
        "wine_data = wine.data[0:130]\r\n",
        "wine_target = wine.target[0:130]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa-FahwtjYgB",
        "outputId": "adb181ba-37e1-4fe8-c4b3-a73b58e300d5"
      },
      "source": [
        "train_x, test_x, train_y, test_y = train_test_split(wine_data, wine_target, test_size = 0.2)\r\n",
        "\r\n",
        "print(len(train_x))\r\n",
        "print(len(test_x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "104\n",
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fngus1IWjYia",
        "outputId": "8c65ebcb-2e4b-4476-d3fc-31353cc951e2"
      },
      "source": [
        "train_x = torch.from_numpy(train_x).float()\r\n",
        "train_y = torch.from_numpy(train_y).long()\r\n",
        "\r\n",
        "test_x = torch.from_numpy(test_x).float()\r\n",
        "test_y = torch.from_numpy(test_y).long()\r\n",
        "\r\n",
        "print(train_x.shape)\r\n",
        "print(train_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([104, 13])\n",
            "torch.Size([104])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J61blhY_Atr7"
      },
      "source": [
        "> Numpy 배열을 텐서로 변환\r\n",
        "* torch.from_numpy()\r\n",
        "\r\n",
        "> 변수들의 합쳐서 하나의 데이터 집합을 생성\r\n",
        "* TensorDataset()\r\n",
        "\r\n",
        "> 데이터 집합을 미니배치로 나누어\r\n",
        "* DataLoader()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQcXNhkmjYnb",
        "outputId": "0e25ca19-80b5-4b5b-b819-c00e455303a2"
      },
      "source": [
        "train = TensorDataset(train_x, train_y)\r\n",
        "\r\n",
        "print(train[0])\r\n",
        "\r\n",
        "# 미니배치로 분할\r\n",
        "train_loader = DataLoader(train, batch_size=16, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([1.3290e+01, 1.9700e+00, 2.6800e+00, 1.6800e+01, 1.0200e+02, 3.0000e+00,\n",
            "        3.2300e+00, 3.1000e-01, 1.6600e+00, 6.0000e+00, 1.0700e+00, 2.8400e+00,\n",
            "        1.2700e+03]), tensor(0))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4usu7ppQHWqF",
        "outputId": "ac7dfe9a-5490-4d23-9335-f768f7c4db3c"
      },
      "source": [
        "for i,b in train_loader:\r\n",
        "  print(b)\r\n",
        "\r\n",
        "  # 임마가 배치사이즈 16개\r\n",
        "  # 전체 텐서는 7개"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1])\n",
            "tensor([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
            "tensor([0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1])\n",
            "tensor([1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1])\n",
            "tensor([0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1])\n",
            "tensor([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0])\n",
            "tensor([1, 1, 0, 1, 1, 0, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYmquNv8jYp0"
      },
      "source": [
        "# 신경망 구성\r\n",
        "class Net(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(Net,self).__init__()\r\n",
        "    self.fc1 = nn.Linear(13,96)\r\n",
        "    self.fc2 = nn.Linear(96,2)\r\n",
        "\r\n",
        "  def forward(self,x):\r\n",
        "    x = F.relu(self.fc1(x))\r\n",
        "    x = self.fc2(x)\r\n",
        "    return F.log_softmax(x)\r\n",
        "\r\n",
        "# 인스턴스 생성\r\n",
        "model = Net()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrat5SaOJewY"
      },
      "source": [
        "> 초기 모듈을 생성\r\n",
        "* nn.Modeule\r\n",
        "\r\n",
        "> 층 (선형변환)\r\n",
        "* nn.Linear()    여기에 bias도 들어간다잉\r\n",
        "\r\n",
        "> 활성화 함수 (앞의 F는 functional의 약자)\r\n",
        "* F.relu()     : Relu함수\r\n",
        "* F.log_softmax   : 로그소프트맥스 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0Vzs220bp-i"
      },
      "source": [
        "> 크로스엔트로피 설명\r\n",
        "* https://hyunw.kim/blog/2017/10/26/Cross_Entropy.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s0dJGU5jYsa",
        "outputId": "0f850361-4068-44cb-ae1f-1e58daf92318"
      },
      "source": [
        "# 모형 학습\r\n",
        "\r\n",
        "# 오차함수 객체\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "# 최적화 담당\r\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)  #경사하강법은 SGD\r\n",
        "\r\n",
        "# 학습시작\r\n",
        "for epoch in range(300):\r\n",
        "  total_loss = 0\r\n",
        "\r\n",
        "  for train_x, train_y in train_loader:\r\n",
        "    # train_x, train_y = Variable(train_x), Variable(train_y)  #이거만다 사용하너\r\n",
        "\r\n",
        "    optimizer.zero_grad()  # 경사초기화\r\n",
        "\r\n",
        "    output = model(train_x)  # 순전파 계산\r\n",
        "\r\n",
        "    loss = criterion(output, train_y)  # 오차 계산\r\n",
        "    loss.backward()  # 역전파 계산\r\n",
        "\r\n",
        "    optimizer.step()  #가중치 업데이트\r\n",
        "\r\n",
        "    total_loss += loss.data  # 누적오차 계산\r\n",
        "  \r\n",
        "  if (epoch+1) % 50 == 0:\r\n",
        "    print(epoch+1, float(total_loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "50 4.787615776062012\n",
            "100 4.797826290130615\n",
            "150 4.849554061889648\n",
            "200 4.814967155456543\n",
            "250 4.765681266784668\n",
            "300 4.781067371368408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t651OyJOjU8-"
      },
      "source": [
        "> 오차 함수\r\n",
        "* nn.CrossEntropyLoss()  # 크로스엔트로피\r\n",
        "\r\n",
        "> 경사하강법으로 최적화\r\n",
        "* optim.SGD(model.parameters(), lr = 0.01)\r\n",
        "\r\n",
        "> 래핑과 계산과정 기록 -- 먼데이거\r\n",
        "* Variable()\r\n",
        "\r\n",
        "> 경사의 합을 구함\r\n",
        "* backward()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1s-fi1j3BKe",
        "outputId": "d48948b7-8481-40aa-98b5-2526b4439767"
      },
      "source": [
        "test_x, test_y = Variable(test_x), Variable(test_y)   # 이거 안해도 문제 없움\r\n",
        "\r\n",
        "# 출력이 0또는 1이 되도록\r\n",
        "result = torch.max(model(test_x).data, 1)[1]\r\n",
        "\r\n",
        "# 측정\r\n",
        "accuracy = sum(test_y.data.numpy() == result.numpy()) / len(test_y.data.numpy())\r\n",
        "accuracy\r\n",
        "\r\n",
        "# 임마는 그냥 최닷값을 뽑아서 1을 넣어주는데 아리송송해"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.46153846153846156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p96H2aIBnbz1"
      },
      "source": [
        "> 최댓값 반환\r\n",
        "* torch.max()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6JnK3nRZDi1",
        "outputId": "d7501dd8-371a-447e-d057-e1a2d3c8afed"
      },
      "source": [
        "torch.max(model(test_x).data, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(values=tensor([-0.5648, -0.5648, -0.5648, -0.5648, -0.5648, -0.5648, -0.5648, -0.5648,\n",
              "        -0.5648, -0.5648, -0.5648, -0.5648, -0.5648, -0.5648, -0.5648, -0.5648,\n",
              "        -0.5648, -0.5648, -0.5648, -0.5648, -0.5648, -0.5648, -0.5648, -0.5648,\n",
              "        -0.5648, -0.5648]), indices=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un6qzzj73BH0",
        "outputId": "36aaae95-95e6-4d15-ffa9-cc1aeca133b4"
      },
      "source": [
        "model(test_x).data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648],\n",
              "        [-0.8404, -0.5648]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEVepUe53BFR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIgCaWg23BC6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1KC2tFb3BAR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}