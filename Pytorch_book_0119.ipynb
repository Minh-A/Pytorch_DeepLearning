{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1월19일.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18KX3hrJDYILyIwVSZ5SUAz0Drb4mwSLx",
      "authorship_tag": "ABX9TyPnM1XY4KvWeNAgvNhLURU5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Minh-A/Pytorch_DeepLearning/blob/main/Pytorch_book_0119.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uJNwCePjI79"
      },
      "source": [
        "RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uGe2CidcE94"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccVTRTvGcE7I"
      },
      "source": [
        "n_hidden = 35\r\n",
        "lr = 0.01\r\n",
        "epochs = 1000\r\n",
        "\r\n",
        "string = \"hello pytorch. how long can a rnn cell remember?\"\r\n",
        "chars = \"abcdefghijklmnopqrstuvwxyz ?!.,:;01\"\r\n",
        "char_list = [i for i in chars]\r\n",
        "n_letters = len(char_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLiGhP3McE4o"
      },
      "source": [
        "def string_to_onehot(string):\r\n",
        "  start = np.zeros(shape=len(char_list), dtype=int)\r\n",
        "  end = np.zeros(shape=len(char_list), dtype=int)\r\n",
        "  start[-2]=1\r\n",
        "  end[-1]=1\r\n",
        "  for i in string:\r\n",
        "    idx = char_list.index(i)\r\n",
        "    zero = np.zeros(shape=n_letters, dtype=int)\r\n",
        "    zero[idx]=1\r\n",
        "    start= np.vstack([start,zero])\r\n",
        "  output= np.vstack([start, end])\r\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQdrHMODcE1w"
      },
      "source": [
        "def onehot_to_word(onehot_1):\r\n",
        "  onehot = torch.Tensor.numpy(onehot_1)\r\n",
        "  return char_list[onehot.argmax()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOBJMJYzcEzI"
      },
      "source": [
        "# 신경망 구성\r\n",
        "class RNN(nn.Module):\r\n",
        "  def __init__(self, input_size, hidden_size, output_size):\r\n",
        "    super(RNN, self).__init__()\r\n",
        "\r\n",
        "    self.input_size = input_size\r\n",
        "    self.hidden_size = hidden_size\r\n",
        "    self.output_size = output_size\r\n",
        "\r\n",
        "    self.i2h = nn.Linear(input_size,hidden_size)\r\n",
        "    self.h2h = nn.Linear(hidden_size, hidden_size)\r\n",
        "    self.i2o = nn.Linear(hidden_size, output_size)\r\n",
        "    self.act_fn = nn.Tanh()\r\n",
        "\r\n",
        "  def forward(self, input, hidden):\r\n",
        "    hidden = self.act_fn(self.i2h(input)+self.h2h(hidden))\r\n",
        "    output = self.i2o(hidden)\r\n",
        "    return output, hidden\r\n",
        "\r\n",
        "  def init_hidden(self):\r\n",
        "    return torch.zeros(1, self.hidden_size)\r\n",
        "\r\n",
        "rnn = RNN(n_letters, n_hidden, n_letters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt5aXaPGcEwY"
      },
      "source": [
        "loss_func = nn.MSELoss()\r\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUkuf-RycEtw"
      },
      "source": [
        "one_hot = torch.from_numpy(string_to_onehot(string)).type_as(torch.FloatTensor())\r\n",
        "\r\n",
        "for i in range(epochs):\r\n",
        "  rnn.zero_grad()\r\n",
        "  total_loss = 0\r\n",
        "  hidden = rnn.init_hidden()\r\n",
        "\r\n",
        "  for j in range(one_hot.size()[0]-1):\r\n",
        "    input_ = one_hot[j:j+1,:]\r\n",
        "    target = one_hot[j+1]\r\n",
        "\r\n",
        "    output, hidden = rnn.forward(input_, hidden)\r\n",
        "    loss = loss_func(output.view(-1), target.view(-1))\r\n",
        "    total_loss += loss\r\n",
        "    input_ = output\r\n",
        "\r\n",
        "  total_loss.backward()\r\n",
        "  optimizer.step()\r\n",
        "\r\n",
        "  if i % 10 == 0:\r\n",
        "    print(total_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDhxJGnvcErH",
        "outputId": "f7c0f3ea-946f-48a8-e30a-c7bd2ed970f1"
      },
      "source": [
        "start = torch.zeros(1, len(char_list))\r\n",
        "start[:,-2] = 1\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "  hidden = rnn.init_hidden()\r\n",
        "  input_ = start\r\n",
        "  output_string = \"\"\r\n",
        "  for i in range(len(string)):\r\n",
        "    output, hidden = rnn.forward(input_, hidden)\r\n",
        "    output_string += onehot_to_word(output.data)\r\n",
        "    input_ = output\r\n",
        "\r\n",
        "print(output_string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello  eto nn  ar  rr pyrb e e n  ar  nn cye erl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v96UdNK6jLvO"
      },
      "source": [
        "GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqjNaq-CwVOY"
      },
      "source": [
        "> 사이트\r\n",
        "* https://drive.google.com/drive/folders/12zphz36T6gEJac6WScnvRN27-f1tfHO1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foY0PAjTl78T",
        "outputId": "1872c7a6-3abb-440e-e240-a4f3dd01fa3b"
      },
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/65/91eab655041e9e92f948cb7302e54962035762ce7b518272ed9d6b269e93/Unidecode-1.1.2-py2.py3-none-any.whl (239kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 22.0MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 28.8MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 20.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 20.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 143kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 174kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 184kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 204kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 215kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 16.5MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8xBhuutl3t6"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import unidecode\r\n",
        "import string\r\n",
        "import random\r\n",
        "import re\r\n",
        "import time, math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGLp-oG4njk6"
      },
      "source": [
        "num_epochs = 2000\r\n",
        "print_every = 100\r\n",
        "plot_every = 10\r\n",
        "chunk_len = 200\r\n",
        "hidden_size = 100\r\n",
        "batch_size = 1\r\n",
        "num_layers = 1\r\n",
        "embedding_size = 70\r\n",
        "lr = 0.002"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmcoyFhYcEoX",
        "outputId": "07a9103b-e502-47d0-f1f6-95a71965b032"
      },
      "source": [
        "all_characters = string.printable\r\n",
        "n_characters = len(all_characters)\r\n",
        "print(all_characters)\r\n",
        "print('num_chars = ', n_characters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
            "\r\u000b\f\n",
            "num_chars =  100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeIkv0lAcEln",
        "outputId": "8f934ebd-7410-4c02-812d-584d67999dae"
      },
      "source": [
        "file = unidecode.unidecode(open('/content/drive/MyDrive/Colab Notebooks/pytorch 책/file/rnn_lstm_gru/shakespeare.txt').read())\r\n",
        "file_len = len(file)\r\n",
        "print('file_len=', file_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file_len= 1115394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDApimL8cEi3",
        "outputId": "4d08ffe8-5c05-44d9-c4af-c7704623ec4c"
      },
      "source": [
        "def random_chunk():\r\n",
        "    start_index = random.randint(0, file_len - chunk_len)\r\n",
        "    end_index = start_index + chunk_len + 1\r\n",
        "    return file[start_index:end_index]\r\n",
        "print(random_chunk())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "e'll none on 't: here has been too much\n",
            "homely foolery already. I know, sir, we weary you.\n",
            "\n",
            "POLIXENES:\n",
            "You weary those that refresh us: pray, let's see\n",
            "these four threes of herdsmen.\n",
            "\n",
            "Servant:\n",
            "One thre\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnX9pnmxcEL3",
        "outputId": "9a168b5c-0932-44df-8a6e-cc3fbca1e18e"
      },
      "source": [
        "def char_tensor(string):\r\n",
        "    tensor = torch.zeros(len(string)).long()\r\n",
        "    for c in range(len(string)):\r\n",
        "        tensor[c] = all_characters.index(string[c])\r\n",
        "    return tensor\r\n",
        "\r\n",
        "print(char_tensor('ABCdef'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([36, 37, 38, 13, 14, 15])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE3PUxddcEJX"
      },
      "source": [
        "def random_training_set():    \r\n",
        "    chunk = random_chunk()\r\n",
        "    inp = char_tensor(chunk[:-1])\r\n",
        "    target = char_tensor(chunk[1:])\r\n",
        "    return inp, target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_68fwuNhcEGv"
      },
      "source": [
        "class RNN(nn.Module):\r\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\r\n",
        "        super(RNN, self).__init__()\r\n",
        "\r\n",
        "        self.input_size = input_size\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.output_size = output_size\r\n",
        "        self.num_layers = num_layers\r\n",
        "        self.embedding_size = embedding_size\r\n",
        "\r\n",
        "        self.encoder = nn.Embedding( input_size, embedding_size )\r\n",
        "        self.rnn = nn.GRU( embedding_size, hidden_size, num_layers)  # RNN, GRU 선택가능\r\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\r\n",
        "           \r\n",
        "    def forward(self, input, hidden):\r\n",
        "        out = self.encoder(input.view(1,-1))\r\n",
        "        out,hidden = self.rnn(out, hidden)\r\n",
        "        out = self.decoder(out.view(batch_size,-1))\r\n",
        "        return out,hidden\r\n",
        "\r\n",
        "    def init_hidden(self):\r\n",
        "        hidden = torch.zeros(self.num_layers, batch_size, hidden_size)\r\n",
        "        return hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rt9iKJZcED_"
      },
      "source": [
        "model = RNN(input_size= n_characters, embedding_size = embedding_size, hidden_size=hidden_size, output_size=n_characters, num_layers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPO3vLmkrBru"
      },
      "source": [
        "inp = char_tensor(\"A\")\r\n",
        "hidden = model.init_hidden()\r\n",
        "out,hidden = model(inp, hidden)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAXLHpE7vAzt"
      },
      "source": [
        "# Loss값 표시\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\r\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltNzWNkTvX7B"
      },
      "source": [
        "def test():\r\n",
        "    start_str = \"m\"\r\n",
        "    inp = char_tensor(start_str)\r\n",
        "    hidden = model.init_hidden()\r\n",
        "    x = inp\r\n",
        "\r\n",
        "    print(start_str,end=\"\")\r\n",
        "    for i in range(200):\r\n",
        "        output,hidden = model(x,hidden)\r\n",
        "\r\n",
        "        output_dist = output.data.view(-1).div(0.8).exp()\r\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\r\n",
        "        predicted_char = all_characters[top_i]\r\n",
        "\r\n",
        "        print(predicted_char,end=\"\")\r\n",
        "\r\n",
        "        x = char_tensor(predicted_char)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yPe4IPPfcEBX",
        "outputId": "79073ffb-03bf-4e5b-96a0-6f2e95e99d54"
      },
      "source": [
        "for i in range(num_epochs):\r\n",
        "    total = char_tensor(random_chunk())\r\n",
        "    inp = total[:-1]\r\n",
        "    label = total[1:]\r\n",
        "    hidden = model.init_hidden()\r\n",
        "\r\n",
        "    loss = torch.tensor([0]).type(torch.FloatTensor)\r\n",
        "    optimizer.zero_grad()\r\n",
        "    for j in range(chunk_len-1):\r\n",
        "        x  = inp[j]\r\n",
        "        y_ = label[j].unsqueeze(0).type(torch.LongTensor)\r\n",
        "        y,hidden = model(x,hidden)\r\n",
        "        loss += loss_func(y,y_)\r\n",
        "\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    if i % 100 == 0:\r\n",
        "        print(\"\\n\",loss/chunk_len,\"\\n\")\r\n",
        "        test()\r\n",
        "        print(\"\\n\",\"=\"*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " tensor([2.6432], grad_fn=<DivBackward0>) \n",
            "\n",
            "m-:Wot he nes pii band fo semerimhingea rete wes, ipe mys ron inen ores a cao iint;.\n",
            "Cls breach mok kon ifso uth in, he hetaree tetis min taner hof tunen ont ins ris:\n",
            "Mith heerars homes vow wil sifad w\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.4349], grad_fn=<DivBackward0>) \n",
            "\n",
            "mZ1VU3WENO:\n",
            "What ald gard suses what woue beny, the som hour his imh thom ourilad lout, asthace thit thicerm\n",
            "Kist to whesh manas mret ang, fovers the wist an the and o she yiven arris sing uor,!\n",
            "Irese \n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.1906], grad_fn=<DivBackward0>) \n",
            "\n",
            "me as gow withen.\n",
            "\n",
            "PAYETAIO:\n",
            "Mater seat merad hand ther reut Lare will mave of not eavLer thay, I tage\n",
            "And me hat a mord!\n",
            "ber.\n",
            "\n",
            "COSINIS:\n",
            "Iy hich mast Cort the heor sas at hhine\n",
            "Whive wall my tCine stre\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.0361], grad_fn=<DivBackward0>) \n",
            "\n",
            "mroms sourd ove be to lory sued ka is be; thet I so shily faelapmire ang the sobesrepwok,\n",
            "For a siek thid well;\n",
            "As be nsware be not forge, Pesseiy, exfised or fa'd yether\n",
            "Ances atten; be ten would in I\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.9062], grad_fn=<DivBackward0>) \n",
            "\n",
            "my shond your and so have, that a the wought the not and counge shour, on.\n",
            "\n",
            "QUEH NTONIUNIU:\n",
            "Not my wo left corte\n",
            "Swer neath for Barte on my phorn, fron are to I pight nay houpt in that thy comuse,\n",
            "\n",
            "INE\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.9016], grad_fn=<DivBackward0>) \n",
            "\n",
            "mQy; sees frown, are litle fard.\n",
            "\n",
            "GORUCTE:\n",
            "Hot conmsand not have if onder onour reach of well father hing with wonds will fond here a ponspelf that the forther; soll.\n",
            "For wood my with prove for for the\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.1599], grad_fn=<DivBackward0>) \n",
            "\n",
            "me to know:\n",
            "Frow'ul coof, for the sit son thou me, the know of thou or morsingle?\n",
            "\n",
            "Sim, them:\n",
            "Firse love, is aday blowning be you with the know's, so shay to he to king, I she with\n",
            "Thy lave knot onter \n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.9878], grad_fn=<DivBackward0>) \n",
            "\n",
            "m<dly feles with Gee?\n",
            "\n",
            "CLONENRE:\n",
            "Then it's good my spinise how roniegs chandy.\n",
            "The sost thy your her that citnem; florter stast some my frevers is the king of thenes of is rother hing,\n",
            "I the me are biv\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.7026], grad_fn=<DivBackward0>) \n",
            "\n",
            "myou her his my slare our out forther,\n",
            "If the commed, to martione reing the king partient thou soulding and his and tay ourth,\n",
            "And on, to hours's stay,\n",
            "God have thou in tike your that orth\n",
            "There of hav\n",
            " ====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-130-3e78d1663676>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-Wui-DxwYB6"
      },
      "source": [
        "GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCw1YrodcD-3"
      },
      "source": [
        "class RNN(nn.Module):\r\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\r\n",
        "        super(RNN, self).__init__()\r\n",
        "        self.input_size = input_size\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.output_size = output_size\r\n",
        "        self.num_layers = num_layers\r\n",
        "        self.embedding_size = embedding_size\r\n",
        "\r\n",
        "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\r\n",
        "        self.rnn = nn.LSTM(self.embedding_size,self.hidden_size,self.num_layers)\r\n",
        "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\r\n",
        "        \r\n",
        "    \r\n",
        "    def forward(self, input, hidden, cell):\r\n",
        "        out = self.encoder(input.view(batch_size,-1))\r\n",
        "        out,(hidden,cell) = self.rnn(out,(hidden,cell))\r\n",
        "        out = self.decoder(out.view(batch_size,-1))\r\n",
        "\r\n",
        "        return out,hidden,cell\r\n",
        "\r\n",
        "    def init_hidden(self):\r\n",
        "        hidden = torch.zeros(self.num_layers,batch_size,self.hidden_size)\r\n",
        "        cell = torch.zeros(self.num_layers,batch_size,self.hidden_size)\r\n",
        "        return hidden,cell\r\n",
        "    \r\n",
        "model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33Q_RWBtcD8I",
        "outputId": "6cb74aec-0a28-44fb-e138-65193a2b7d85"
      },
      "source": [
        "inp = char_tensor(\"A\")\r\n",
        "print(inp)\r\n",
        "hidden,cell = model.init_hidden()\r\n",
        "print(hidden.size())\r\n",
        "\r\n",
        "out,hidden,cell = model(inp,hidden,cell)\r\n",
        "print(out.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([36])\n",
            "torch.Size([1, 1, 100])\n",
            "torch.Size([1, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5sPZzddcD5n"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\r\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TR4eyoncD3P"
      },
      "source": [
        "def test():\r\n",
        "    start_str = \"b\"\r\n",
        "    inp = char_tensor(start_str)\r\n",
        "    hidden,cell = model.init_hidden()\r\n",
        "    x = inp\r\n",
        "\r\n",
        "    print(start_str,end=\"\")\r\n",
        "    for i in range(200):\r\n",
        "        output,hidden,cell = model(x,hidden,cell)\r\n",
        "\r\n",
        "        output_dist = output.data.view(-1).div(0.8).exp()\r\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\r\n",
        "        predicted_char = all_characters[top_i]\r\n",
        "\r\n",
        "        print(predicted_char,end=\"\")\r\n",
        "\r\n",
        "        x = char_tensor(predicted_char)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sHY-0N72cD0n",
        "outputId": "53e4919a-046c-4f4f-aa3a-fd7bcd0a3070"
      },
      "source": [
        "for i in range(num_epochs):\r\n",
        "    inp,label = random_training_set()\r\n",
        "    hidden,cell = model.init_hidden()\r\n",
        "\r\n",
        "    loss = torch.tensor([0]).type(torch.FloatTensor)\r\n",
        "    optimizer.zero_grad()\r\n",
        "    for j in range(chunk_len-1):\r\n",
        "        x  = inp[j]\r\n",
        "        y_ = label[j].unsqueeze(0).type(torch.LongTensor)\r\n",
        "        y,hidden,cell = model(x,hidden,cell)\r\n",
        "        loss += loss_func(y,y_)\r\n",
        "\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "    \r\n",
        "    if i % 100 == 0:\r\n",
        "        print(\"\\n\",loss/chunk_len,\"\\n\")\r\n",
        "        test()\r\n",
        "        print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " tensor([4.5730], grad_fn=<DivBackward0>) \n",
            "\n",
            "b=seA?.zF-CQS*\\O\tkE;LoQSRO/V1th/9k\" ]FxXo'zemEs~N1I|e3L_ZbEr62Cj W'ZvdDtjwV&.<bx_?K\u000bA`BR=oW40\n",
            ",&nHHMPy[U\n",
            "8$`\n",
            "\n",
            "#C\f0T>\fM*Y\n",
            "94}hT*0E\u000brfVmm$FD]{V>`lD=!\fZpC6!\rc0lw[)9~F:.r7 >g`/yB/mo,$FWxN\"%EAAk#eWM@h\u000bKcP!%\n",
            "\n",
            "\n",
            "\n",
            " tensor([2.5028], grad_fn=<DivBackward0>) \n",
            "\n",
            "b ffesarees sugi\n",
            "H' rosmt horluld bithe fe yare om, hree the Fhit noth gye a ouhe\n",
            "CGv hany peabeu care'unou hice Tslvoum windI\n",
            "myy\n",
            "\n",
            "Traatos ion iatr thecavit the the are thim unaaind bonr, miu sher tep\n",
            "\n",
            "\n",
            "\n",
            " tensor([2.5394], grad_fn=<DivBackward0>) \n",
            "\n",
            "bivle hin, wate deanen\n",
            "ore alin togrouit enmer, yout wou hacoung wist do fat withr to that starere Ie she, breert arente gind,\n",
            "Whasrou, lime noul ther and our luld cour inpe falt wins thane bighat yono\n",
            "\n",
            "\n",
            "\n",
            " tensor([2.2321], grad_fn=<DivBackward0>) \n",
            "\n",
            "bane bed,\n",
            "I wand coret bus.\n",
            "Bu seme\n",
            "Th hathe atianes?\n",
            "To shilll whaeved dony of riernsan co salld and all?\n",
            "fotringy bkecekiB tereis\n",
            "When ar nnaser, I thaghem dathe ith thesek,\n",
            "Sron shatlan and:\n",
            "so cade\n",
            "\n",
            "\n",
            "\n",
            " tensor([1.8997], grad_fn=<DivBackward0>) \n",
            "\n",
            "bh: of we ore,\n",
            "And thament tho ther the there . whet the wo serwiln the ware, youn macl yus mornour yore the gour not shindeu: Folance bang mem will llem youls roeut, ore ast\n",
            "Wou my hand the diy sem an\n",
            "\n",
            "\n",
            "\n",
            " tensor([2.2737], grad_fn=<DivBackward0>) \n",
            "\n",
            "bke to sist whte foed eas ay take theasses the is whe the for thise ah hoon, are, shacy!\n",
            "He of the shaid san brakrer, hat tor suree; fur he vastu than me gigern.\n",
            "\n",
            "FI RICRINIO:\n",
            "The doulestiss this lepsm\n",
            "\n",
            "\n",
            "\n",
            " tensor([2.2115], grad_fn=<DivBackward0>) \n",
            "\n",
            "bem are your wis that to and wear hig whe the say,\n",
            "\n",
            "LARIA:\n",
            "O then lonath and,\n",
            "In :e\n",
            "Do, ofee hing renlelingered in thas say wild sertent hit cor gor's the all mo por endsur tou ty him the *ond wes at m\n",
            "\n",
            "\n",
            "\n",
            " tensor([2.0796], grad_fn=<DivBackward0>) \n",
            "\n",
            "bruist friguth.\n",
            "\n",
            "LAULAI:\n",
            "So, bather doond.\n",
            "Aus.\n",
            "\n",
            "LADRO:\n",
            "She me mpeak the hish in now sier'lts the hach of muchave, be etre forith, are there be tis mirt?\n",
            "\n",
            "ARNID:\n",
            "When thatt hich thad for her the mared \n",
            "\n",
            "\n",
            "\n",
            " tensor([1.9539], grad_fn=<DivBackward0>) \n",
            "\n",
            "bnife I lood fanger?\n",
            "So may my not s lirien\n",
            "And shath furtor I wit horne my meed stirfly he coumr?\n",
            "Bed with a and,\n",
            "I thach bed and enow shat I wis, sofo to sif ang bescrave offrrabine streece,\n",
            "Thas gra\n",
            "\n",
            "\n",
            "\n",
            " tensor([1.9296], grad_fn=<DivBackward0>) \n",
            "\n",
            "bes my thy shave nomner of the wint;\n",
            "Mim Busp ets of eae strom pring shaln meaw be soor oe he sid we por so all for thy ore in wo or to to maur thim bur come, in laar, on on Carlcuen mor besnching dule\n",
            "\n",
            "\n",
            "\n",
            " tensor([2.1371], grad_fn=<DivBackward0>) \n",
            "\n",
            "btas pratily my the ould whou wathiur to stale the sared is beter our Cofenter hay but goring.\n",
            "\n",
            "HAREN:\n",
            "May, farke, bowner.\n",
            "\n",
            "HARINCE:\n",
            "I lut mored, head is foor bite\n",
            "Youl so of frenone, bong wour the thi\n",
            "\n",
            "\n",
            "\n",
            " tensor([1.9143], grad_fn=<DivBackward0>) \n",
            "\n",
            "bred thay pither the he shave lot the my I and to be\n",
            "On hill or with wis serrow;\n",
            "I will for to gailfus fall is fands,\n",
            "Then\n",
            "No me is me have prest may for\n",
            "Have in beath whe that that bloon, fich moror Y\n",
            "\n",
            "\n",
            "\n",
            " tensor([1.8873], grad_fn=<DivBackward0>) \n",
            "\n",
            "bly cucases my thour on ellow how aft blove lames the the gove preved\n",
            "What wo agaed; sith my the lain be,\n",
            "Are nom held I wigres, and will the mast my here mand,\n",
            "And so grove that our the some in came y\n",
            "\n",
            "\n",
            "\n",
            " tensor([1.7743], grad_fn=<DivBackward0>) \n",
            "\n",
            "breir, ny my mey;\n",
            "I whou thith some\n",
            "This lise the all wemy my smadine is lerest?\n",
            "\n",
            "LANRTIS:\n",
            "In cor,\n",
            "The heake doed. a cantury I my chad, to in stence.\n",
            "And me mame dello,\n",
            "Ou ale her fare rust comes.\n",
            "Heac\n",
            "\n",
            "\n",
            "\n",
            " tensor([1.7379], grad_fn=<DivBackward0>) \n",
            "\n",
            "brentine her hast whis a guth beave,\n",
            "Whout sive as the sto hous,\n",
            "Whour, thour to doo whom shall be 'lemee to burce, the as lime. Mare you shight,\n",
            "O, do risce thould.\n",
            "\n",
            "GULOUCAS:\n",
            "Cubord.\n",
            "\n",
            "dORINGTINCEND I\n",
            "\n",
            "\n",
            "\n",
            " tensor([1.8916], grad_fn=<DivBackward0>) \n",
            "\n",
            "bem that liilour them someng thou my for pantess\n",
            "Hese you, st\n",
            "Whot fenous word bee\n",
            "And renoke sampolt?\n",
            "\n",
            "LUCUSE:\n",
            "And for oose, nose be. the prasep! And by ceads and or for my paught not myen,\n",
            "Nou dowome\n",
            "\n",
            "\n",
            "\n",
            " tensor([1.8178], grad_fn=<DivBackward0>) \n",
            "\n",
            "bus sount my ming,\n",
            "I'll grave\n",
            "so, I mpone if and semale beat!\n",
            "\n",
            "LUCIO:\n",
            "Whil not of the not, beas thee son and ofle that preathought to lords of beomple here his beath theuds sery\n",
            "Ancritian:\n",
            "You know but\n",
            "\n",
            "\n",
            "\n",
            " tensor([1.9697], grad_fn=<DivBackward0>) \n",
            "\n",
            "ban, with the be andses the pent ather to there to yould andeld his your grought to goda the louth but mores,\n",
            "Wath with hom if wet be Kaned,\n",
            "Her aste her the a the word bet of untlito\n",
            "The pory thack.\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-135-b0ec548914b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-131-99d6542f6597>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, cell)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 582\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    583\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2OhdJsbcDyR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36LNkjJecDv4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SblNPRi4cB3Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}